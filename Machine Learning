Good references:
https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss


How to correct loss in ML model
___


Various training methods to train a ML model
___
 1. k-Nearest Neighbors (k-NN)  
    for kNN, there is no training step because there is no model to build. 
    Template matching & interpolation is all that is going on in kNN. 
    As no model is built, there is nothing to validate
    
 2. Logistic Regression
 3. Support Vector Machines (SVMs)
 4. Decision Trees
 5. Convolutional Neural Networks (CNNs)


 What’s the trade-off between bias and variance?
 ___
 Variance is defined in Statistics, the expectation of the squared deviation of a random variable from its mean
 Bias is the difference between the true label and our prediction. 
 
 
 
 What is the difference between supervised and unsupervised machine learning?

 How is KNN different from k-means clustering?

 Explain how a ROC curve works.

 Define precision and recall.

 What is Bayes’ Theorem? How is it useful in a machine learning context?
 Why is “Naive” Bayes naive?

 Explain the difference between L1 and L2 regularization.

 What’s your favorite algorithm, and can you explain it to me in less than a minute?
 What’s the difference between Type I and Type II error?

 What’s a Fourier transform?

 What’s the difference between probability and likelihood?
 What is deep learning, and how does it contrast with other machine learning algorithms?

 What’s the difference between a generative and discriminative model?

 How is a decision tree pruned?
 Which is more important to you– model accuracy, or model performance?

 How would you handle an imbalanced dataset?

 When should you use classification over regression?

 How do you ensure you’re not overfitting with a model? 
